{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "程式參考並修改自:\n",
    "> https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5  \n",
    "\n",
    "解釋程式如何改進之參考文章:\n",
    "> https://david-exiga.medium.com/music-generation-using-lstm-neural-networks-44f6780a4c5  \n",
    "\n",
    "額外的中文程式解釋:\n",
    "> https://github.com/xitu/gold-miner/blob/master/TODO1/how-to-generate-music-using-a-lstm-neural-network-in-keras.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安裝 music21  # music21 介紹: https://juejin.cn/post/7063827463058489352\n",
    "! pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取檔案用\n",
    "import glob\n",
    "# array processing\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "# keras for building deep learning model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 從目錄下的 midi 文件中獲取所有的音符和和弦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./midi_songs\\appass_1_format0.mid\n",
      "Parsing ./midi_songs\\beethoven_les_adieux_2_format0.mid\n",
      "Parsing ./midi_songs\\beethoven_opus10_3_format0.mid\n",
      "Parsing ./midi_songs\\beethoven_opus22_1_format0.mid\n",
      "Parsing ./midi_songs\\beethoven_opus22_3_format0.mid\n",
      "Parsing ./midi_songs\\elise_format0.mid\n"
     ]
    }
   ],
   "source": [
    "## \"\"\" 從目錄下的 midi 文件中獲取所有的音符和和弦 \"\"\"\n",
    "\n",
    "# 使用music21來進行midi檔案的操作\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "# music21 介紹: https://juejin.cn/post/7063827463058489352\n",
    "\n",
    "\n",
    "# 使用glob讀取midi檔案，路徑代號為:\n",
    "# \"./\"               -使用當前執行程式所在的資料夾\n",
    "# \"midi_songs/\"      -名為midi_songs資料夾\n",
    "# \"*.mid\"            -所有結尾為的.mid檔案\n",
    "\n",
    "\n",
    "# note是音符，將midi檔案裡的音符讀進這個list\n",
    "notes = []\n",
    "\n",
    "for file in glob.glob(\"./midi_songs/*.mid\"): # 讀取目錄檔案路徑中所有midi檔案\n",
    "    \n",
    "    # 使用 music21 解析midi文件\n",
    "    midi = converter.parse(file)\n",
    "\n",
    "    print(\"Parsing %s\" % file)\n",
    "\n",
    "    notes_to_parse = None\n",
    "\n",
    "    try: #如果有樂器部分，取第一個樂器\n",
    "        s2 = instrument.partitionByInstrument(midi)\n",
    "        notes_to_parse = s2.parts[0].recurse() \n",
    "    except: #如果沒有樂器部分，直接取note\n",
    "        notes_to_parse = midi.flat.notes\n",
    "\n",
    "    for element in notes_to_parse:\n",
    "        #print(element)\n",
    "        # 如果是 Note 型別，取音調\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        # 如果是 Chord 型別，取音調的序號,存int型別比較容易處理\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備神經網絡使用的輸入輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 項目解釋 ======\n",
      "\n",
      "notes: 是一個(list)，當中以(字串)儲存所有樂譜的音符\n",
      "樂譜裡的音符總共有: 7506 個 \n",
      "樂譜裡[音符種類]共有: 221 個\n",
      "音符種類名稱分別是: ['0', '0.1', '0.2', '0.2.4', '0.2.5.8', '0.2.6', '0.3', '0.3.5', '0.3.5.8', '0.3.6', '0.3.6.8', '0.3.7', '0.4', '0.4.7', '0.4.7.8', '0.5', '0.6', '1', '1.2', '1.2.4.7.10', '1.3', '1.4', '1.4.7', '1.4.7.10', '1.4.7.9', '1.5', '1.5.8', '1.7', '10', '10.0', '10.0.3', '10.0.4', '10.1', '10.1.4', '10.1.5', '10.11', '10.2', '10.2.4', '10.2.5', '10.3', '11', '11.0', '11.0.2', '11.1.2.4.7', '11.2', '11.2.5', '11.2.5.7', '11.3', '11.4', '2', '2.3', '2.4', '2.4.6', '2.4.7', '2.5', '2.5.7', '2.5.7.10', '2.5.7.8', '2.5.8', '2.5.8.10', '2.5.8.11', '2.5.9', '2.6', '2.6.9', '2.6.9.10', '2.7', '2.7.8', '2.8', '3', '3.4', '3.4.7.10', '3.5', '3.5.9', '3.6', '3.6.10', '3.6.9.11', '3.7', '3.7.10', '3.8', '3.9', '4', '4.10', '4.5', '4.5.7.10', '4.5.7.9.10.0', '4.6.7.10', '4.6.9', '4.7', '4.7.10', '4.7.10.0', '4.7.11', '4.7.9', '4.8', '4.8.11', '4.9', '5', '5.10', '5.11', '5.6', '5.7', '5.7.10', '5.7.10.0', '5.7.11', '5.7.8', '5.7.8.0', '5.7.9', '5.8', '5.8.0', '5.8.10', '5.8.11', '5.8.11.0', '5.9', '5.9.0', '5.9.10', '6', '6.10.1', '6.7.9.0', '6.8.0', '6.9', '6.9.0', '6.9.0.2', '6.9.1', '6.9.11', '7', '7.0', '7.10', '7.10.0', '7.10.1', '7.10.1.3', '7.10.2', '7.11', '7.11.0', '7.11.2', '7.8', '7.8.0', '7.9', '7.9.0', '7.9.0.2', '7.9.10.2', '8', '8.0', '8.0.3', '8.10', '8.10.2', '8.11', '9', '9.0', '9.0.2', '9.0.2.4', '9.0.3', '9.0.3.5', '9.0.4', '9.1', '9.1.4', '9.10', '9.10.0', '9.10.2', '9.11', '9.11.0.2.5', '9.11.2', '9.2', 'A1', 'A2', 'A3', 'A4', 'A5', 'B-1', 'B-2', 'B-3', 'B-4', 'B-5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C#2', 'C#3', 'C#4', 'C#5', 'C#6', 'C2', 'C3', 'C4', 'C5', 'C6', 'D2', 'D3', 'D4', 'D5', 'D6', 'E-2', 'E-3', 'E-4', 'E-5', 'E-6', 'E2', 'E3', 'E4', 'E5', 'E6', 'F#2', 'F#3', 'F#4', 'F#5', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'G#1', 'G#2', 'G#3', 'G#4', 'G#5', 'G1', 'G2', 'G3', 'G4', 'G5']\n",
      "音符種類與對應的號碼: {'0': 0, '0.1': 1, '0.2': 2, '0.2.4': 3, '0.2.5.8': 4, '0.2.6': 5, '0.3': 6, '0.3.5': 7, '0.3.5.8': 8, '0.3.6': 9, '0.3.6.8': 10, '0.3.7': 11, '0.4': 12, '0.4.7': 13, '0.4.7.8': 14, '0.5': 15, '0.6': 16, '1': 17, '1.2': 18, '1.2.4.7.10': 19, '1.3': 20, '1.4': 21, '1.4.7': 22, '1.4.7.10': 23, '1.4.7.9': 24, '1.5': 25, '1.5.8': 26, '1.7': 27, '10': 28, '10.0': 29, '10.0.3': 30, '10.0.4': 31, '10.1': 32, '10.1.4': 33, '10.1.5': 34, '10.11': 35, '10.2': 36, '10.2.4': 37, '10.2.5': 38, '10.3': 39, '11': 40, '11.0': 41, '11.0.2': 42, '11.1.2.4.7': 43, '11.2': 44, '11.2.5': 45, '11.2.5.7': 46, '11.3': 47, '11.4': 48, '2': 49, '2.3': 50, '2.4': 51, '2.4.6': 52, '2.4.7': 53, '2.5': 54, '2.5.7': 55, '2.5.7.10': 56, '2.5.7.8': 57, '2.5.8': 58, '2.5.8.10': 59, '2.5.8.11': 60, '2.5.9': 61, '2.6': 62, '2.6.9': 63, '2.6.9.10': 64, '2.7': 65, '2.7.8': 66, '2.8': 67, '3': 68, '3.4': 69, '3.4.7.10': 70, '3.5': 71, '3.5.9': 72, '3.6': 73, '3.6.10': 74, '3.6.9.11': 75, '3.7': 76, '3.7.10': 77, '3.8': 78, '3.9': 79, '4': 80, '4.10': 81, '4.5': 82, '4.5.7.10': 83, '4.5.7.9.10.0': 84, '4.6.7.10': 85, '4.6.9': 86, '4.7': 87, '4.7.10': 88, '4.7.10.0': 89, '4.7.11': 90, '4.7.9': 91, '4.8': 92, '4.8.11': 93, '4.9': 94, '5': 95, '5.10': 96, '5.11': 97, '5.6': 98, '5.7': 99, '5.7.10': 100, '5.7.10.0': 101, '5.7.11': 102, '5.7.8': 103, '5.7.8.0': 104, '5.7.9': 105, '5.8': 106, '5.8.0': 107, '5.8.10': 108, '5.8.11': 109, '5.8.11.0': 110, '5.9': 111, '5.9.0': 112, '5.9.10': 113, '6': 114, '6.10.1': 115, '6.7.9.0': 116, '6.8.0': 117, '6.9': 118, '6.9.0': 119, '6.9.0.2': 120, '6.9.1': 121, '6.9.11': 122, '7': 123, '7.0': 124, '7.10': 125, '7.10.0': 126, '7.10.1': 127, '7.10.1.3': 128, '7.10.2': 129, '7.11': 130, '7.11.0': 131, '7.11.2': 132, '7.8': 133, '7.8.0': 134, '7.9': 135, '7.9.0': 136, '7.9.0.2': 137, '7.9.10.2': 138, '8': 139, '8.0': 140, '8.0.3': 141, '8.10': 142, '8.10.2': 143, '8.11': 144, '9': 145, '9.0': 146, '9.0.2': 147, '9.0.2.4': 148, '9.0.3': 149, '9.0.3.5': 150, '9.0.4': 151, '9.1': 152, '9.1.4': 153, '9.10': 154, '9.10.0': 155, '9.10.2': 156, '9.11': 157, '9.11.0.2.5': 158, '9.11.2': 159, '9.2': 160, 'A1': 161, 'A2': 162, 'A3': 163, 'A4': 164, 'A5': 165, 'B-1': 166, 'B-2': 167, 'B-3': 168, 'B-4': 169, 'B-5': 170, 'B1': 171, 'B2': 172, 'B3': 173, 'B4': 174, 'B5': 175, 'C#2': 176, 'C#3': 177, 'C#4': 178, 'C#5': 179, 'C#6': 180, 'C2': 181, 'C3': 182, 'C4': 183, 'C5': 184, 'C6': 185, 'D2': 186, 'D3': 187, 'D4': 188, 'D5': 189, 'D6': 190, 'E-2': 191, 'E-3': 192, 'E-4': 193, 'E-5': 194, 'E-6': 195, 'E2': 196, 'E3': 197, 'E4': 198, 'E5': 199, 'E6': 200, 'F#2': 201, 'F#3': 202, 'F#4': 203, 'F#5': 204, 'F1': 205, 'F2': 206, 'F3': 207, 'F4': 208, 'F5': 209, 'F6': 210, 'G#1': 211, 'G#2': 212, 'G#3': 213, 'G#4': 214, 'G#5': 215, 'G1': 216, 'G2': 217, 'G3': 218, 'G4': 219, 'G5': 220} \n",
      "\n",
      "===================\n",
      "\n",
      "notes: \t共有: 7506 項字串\n",
      "notes 中的每 100 項音符轉換成一組訓練資料 \n",
      "network_input:  共有: 7406 組list，每組裡有: 100 項數字\n",
      "network_output: 共有: 7406 項數字，每項都是input的再後面一項的音符數字\n",
      "\n",
      "===================\n",
      "\n",
      "notes 第 sequence_length -10 往後10項 音符名稱分別是:\t ['2.6.9.10', 'A4', 'F#4', 'A4', 'C5', 'E-5', 'D5', 'C5', 'B-4', 'A4']\n",
      "notes 第 sequence_length -10 往後10項 音符對應的數字是:\t [64, 164, 203, 164, 184, 194, 189, 184, 169, 164]\n",
      "\n",
      "network_input 第0組 的 最後10 項號碼:\t [64, 164, 203, 164, 184, 194, 189, 184, 169, 164]\n",
      "network_input 第1組 的 最後10 項號碼:\t [164, 203, 164, 184, 194, 189, 184, 169, 164, 184]\n",
      "network_input 第2組 的 最後10 項號碼:\t [203, 164, 184, 194, 189, 184, 169, 164, 184, 204]\n",
      "network_output 的第 0~2 項號碼: [184, 204, 165]\n",
      "\n",
      "===== 資料重塑後 =========\n",
      "\n",
      "normalized_input.shape: (7406, 100, 1)\n",
      "network_output.shape: (7406, 221)\n"
     ]
    }
   ],
   "source": [
    "## \"\"\" 準備神經網絡使用的輸入輸出 \"\"\"\n",
    "\n",
    "# 獲取音符種類名稱的數量\n",
    "n_vocab = len(set(notes))\n",
    "# 獲得排序後的音符種類名稱\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "# 創建一個字典，把每個音符轉換分配一個對應的數字號碼 ex:(C4 > 25)，利於訓練\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "print(\"\\n===== 項目解釋 ======\\n\")\n",
    "print(\"notes: 是一個(list)，當中以(字串)儲存所有樂譜的音符\")\n",
    "print(f\"樂譜裡的所有音符總共有: %d 個 \"         % len(notes))\n",
    "print(f\"樂譜裡[音符種類]共有: %d 個\"      %  n_vocab)\n",
    "print(f\"音符種類名稱分別是: %s\"            %  pitchnames)\n",
    "print(f\"音符種類與對應的號碼: {note_to_int} \"  )\n",
    "\n",
    "\n",
    "\n",
    "# 訓練輸入序列的長度(輸入音符的個數) \n",
    "sequence_length = 100 \n",
    "\n",
    "network_input = [] #創建輸入序列\n",
    "network_output = [] #創建輸出序列\n",
    "\n",
    "# =====使用notes裡的音符創建輸入序列和相應的輸出=====\n",
    "for i in range(0, len(notes) - sequence_length, 1):\n",
    "    sequence_in = notes[i:i + sequence_length]  # [0 ~ length-1 項音符], [1 ~ length 項音符], [1 ~ length+1項音符]....\n",
    "    sequence_out = notes[i + sequence_length]   # 第length項音符, 第length + 1項音符,第length + 2項音符...\n",
    "\n",
    "    network_input.append([note_to_int[char] for char in sequence_in]) # 加入, 把sequence_in裡的音符翻譯成的號碼\n",
    "    network_output.append(note_to_int[sequence_out])    # 作為預測用的 label\n",
    "\n",
    "print(\"\\n===================\\n\")\n",
    "print(f\"notes: \\t共有: {len(notes)} 項字串\")\n",
    "print(f\"notes 中的每 {sequence_length} 項音符轉換成一組訓練資料 \")\n",
    "print(f\"network_input:  共有: {len(network_input)} 組list，每組裡有: {len(network_input[0])} 項數字\")\n",
    "print(f\"network_output: 共有: {len(network_output)} 項數字，每項都是input的再後面一項的音符數字\")\n",
    "print(\"\\n===================\\n\")\n",
    "print(\"notes 第 sequence_length -10 往後10項 音符名稱分別是:\\t\",notes[sequence_length-10:sequence_length])\n",
    "print(\"notes 第 sequence_length -10 往後10項 音符對應的數字是:\\t\", [note_to_int[char] for char in notes[sequence_length-10:sequence_length]])\n",
    "print(\"\")\n",
    "print(f\"network_input 第0組 的 最後10 項號碼:\\t\",network_input[0][sequence_length-10:sequence_length])\n",
    "print(f\"network_input 第1組 的 最後10 項號碼:\\t\",network_input[1][sequence_length-10:sequence_length])\n",
    "print(f\"network_input 第2組 的 最後10 項號碼:\\t\",network_input[2][sequence_length-10:sequence_length])\n",
    "print(\"network_output 的第 0~2 項號碼:\",network_output[0:3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_patterns = len(network_input)\n",
    "# =====將輸入重塑為與 LSTM 層兼容的格式=====\n",
    "normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "\n",
    "# 正規化輸入\n",
    "normalized_input = normalized_input / float(n_vocab)\n",
    "#輸出bool矩陣，以n_vocab維度表示一個數字，用以配合categorical_crossentropy 算法\n",
    "# to_categorical解釋: https://blog.csdn.net/moyu123456789/article/details/83444140\n",
    "network_output = to_categorical(network_output,n_vocab)\n",
    "\n",
    "print(\"\\n===== 資料重塑後 =========\\n\")\n",
    "print(\"normalized_input.shape:\",normalized_input.shape)\n",
    "print(\"network_output.shape:\",network_output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 創建神經網絡的結構 \n",
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 512)          1052672   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100, 512)          2099200   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 512)               2099200   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 221)               56797     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 221)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,442,269\n",
      "Trainable params: 5,440,733\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##\"\"\" 創建神經網絡的結構 \"\"\"\n",
    "#LSTM\n",
    "\n",
    "\n",
    "# https://huhuhang.com/post/machine-learning/lstm-return-sequences-state\n",
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(normalized_input.shape[1], normalized_input.shape[2]),\n",
    "        recurrent_dropout=0.1,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.1,))\n",
    "model.add(LSTM(512))\n",
    "model.add(BatchNorm())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNorm())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練神經網絡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "39/39 [==============================] - 49s 1s/step - loss: 2.2092 - val_loss: 6.0674\n",
      "Epoch 2/30\n",
      "39/39 [==============================] - 48s 1s/step - loss: 2.0219 - val_loss: 6.2259\n",
      "Epoch 3/30\n",
      "39/39 [==============================] - 51s 1s/step - loss: 1.8086 - val_loss: 6.3437\n",
      "Epoch 4/30\n",
      "39/39 [==============================] - 48s 1s/step - loss: 1.6536 - val_loss: 6.3104\n",
      "Epoch 5/30\n",
      "39/39 [==============================] - 51s 1s/step - loss: 1.4810 - val_loss: 6.4561\n",
      "Epoch 6/30\n",
      "39/39 [==============================] - 51s 1s/step - loss: 1.2925 - val_loss: 6.4439\n",
      "Epoch 7/30\n",
      "39/39 [==============================] - 49s 1s/step - loss: 1.1623 - val_loss: 6.8118\n",
      "Epoch 8/30\n",
      "39/39 [==============================] - 49s 1s/step - loss: 1.0172 - val_loss: 6.9018\n",
      "Epoch 9/30\n",
      "39/39 [==============================] - 49s 1s/step - loss: 0.9119 - val_loss: 6.7380\n",
      "Epoch 10/30\n",
      "39/39 [==============================] - 49s 1s/step - loss: 0.8009 - val_loss: 6.8738\n",
      "Epoch 11/30\n",
      "39/39 [==============================] - 49s 1s/step - loss: 0.6767 - val_loss: 7.2679\n",
      "Epoch 12/30\n",
      "39/39 [==============================] - 50s 1s/step - loss: 0.6031 - val_loss: 6.8749\n",
      "Epoch 13/30\n",
      "39/39 [==============================] - 49s 1s/step - loss: 0.5348 - val_loss: 7.2409\n",
      "Epoch 14/30\n",
      "39/39 [==============================] - 50s 1s/step - loss: 0.4635 - val_loss: 7.3044\n",
      "Epoch 15/30\n",
      "39/39 [==============================] - 50s 1s/step - loss: 0.4131 - val_loss: 7.3578\n",
      "Epoch 16/30\n",
      "39/39 [==============================] - 49s 1s/step - loss: 0.3593 - val_loss: 7.2626\n",
      "Epoch 17/30\n",
      "39/39 [==============================] - 50s 1s/step - loss: 0.2978 - val_loss: 7.4961\n",
      "Epoch 18/30\n",
      "39/39 [==============================] - 50s 1s/step - loss: 0.2800 - val_loss: 7.5298\n",
      "Epoch 19/30\n",
      "39/39 [==============================] - 48s 1s/step - loss: 0.2419 - val_loss: 7.4507\n",
      "Epoch 20/30\n",
      "39/39 [==============================] - 48s 1s/step - loss: 0.2161 - val_loss: 7.6574\n",
      "Epoch 21/30\n",
      "39/39 [==============================] - 48s 1s/step - loss: 0.1948 - val_loss: 7.9252\n",
      "Epoch 22/30\n",
      "39/39 [==============================] - 49s 1s/step - loss: 0.1804 - val_loss: 7.9210\n",
      "Epoch 23/30\n",
      "39/39 [==============================] - 51s 1s/step - loss: 0.1457 - val_loss: 7.8589\n",
      "Epoch 24/30\n",
      "39/39 [==============================] - 50s 1s/step - loss: 0.1510 - val_loss: 8.4782\n",
      "Epoch 25/30\n",
      "39/39 [==============================] - 49s 1s/step - loss: 0.1310 - val_loss: 8.1808\n",
      "Epoch 26/30\n",
      "39/39 [==============================] - 50s 1s/step - loss: 0.1137 - val_loss: 8.0425\n",
      "Epoch 27/30\n",
      "39/39 [==============================] - 48s 1s/step - loss: 0.1070 - val_loss: 8.3044\n",
      "Epoch 28/30\n",
      "39/39 [==============================] - 49s 1s/step - loss: 0.0994 - val_loss: 8.4072\n",
      "Epoch 29/30\n",
      "39/39 [==============================] - 48s 1s/step - loss: 0.1031 - val_loss: 8.6000\n",
      "Epoch 30/30\n",
      "39/39 [==============================] - 49s 1s/step - loss: 0.0835 - val_loss: 8.2891\n"
     ]
    }
   ],
   "source": [
    "## \"\"\" 訓練神經網絡 \"\"\"\n",
    "# callbacks = ModelCheckpoint('model{epoch:03d}.weights.h5', save_weights_only=True)\n",
    "\n",
    "model.fit(normalized_input, network_output, epochs=1, batch_size=128 ,callbacks=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根據選定的音符起始點，從神經網絡預測下一個音符並生成樂譜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "196\n",
      "206\n",
      "60\n",
      "188\n",
      "160\n",
      "207\n",
      "6\n",
      "183\n",
      "160\n",
      "207\n",
      "141\n",
      "219\n",
      "219\n",
      "219\n",
      "59\n",
      "168\n",
      "141\n",
      "141\n",
      "184\n",
      "141\n",
      "184\n",
      "169\n",
      "214\n",
      "219\n",
      "167\n",
      "214\n",
      "207\n",
      "199\n",
      "106\n",
      "214\n",
      "166\n",
      "168\n",
      "181\n",
      "177\n",
      "168\n",
      "172\n",
      "220\n",
      "204\n",
      "206\n",
      "169\n",
      "207\n",
      "207\n",
      "194\n",
      "207\n",
      "163\n",
      "207\n",
      "204\n",
      "167\n",
      "167\n",
      "207\n",
      "182\n",
      "172\n",
      "218\n",
      "162\n",
      "207\n",
      "162\n",
      "197\n",
      "219\n",
      "201\n",
      "206\n",
      "177\n",
      "199\n",
      "176\n",
      "188\n",
      "186\n",
      "167\n",
      "187\n",
      "170\n",
      "212\n",
      "220\n",
      "212\n",
      "186\n",
      "220\n",
      "179\n",
      "197\n",
      "207\n",
      "201\n",
      "196\n",
      "185\n",
      "207\n",
      "176\n",
      "170\n",
      "220\n",
      "170\n",
      "212\n",
      "220\n",
      "217\n",
      "175\n",
      "185\n",
      "206\n",
      "217\n",
      "206\n",
      "185\n",
      "165\n",
      "184\n",
      "176\n",
      "220\n",
      "204\n",
      "204\n",
      "220\n"
     ]
    }
   ],
   "source": [
    "##\"\"\" 根據選定的音符起始點，從神經網絡預測下一個音符並生成樂譜 \"\"\"\n",
    "\n",
    "# 從 network_input 中選擇一個組隨機序列作為預測的起點\n",
    "start = numpy.random.randint(0, len(network_input)-1)\n",
    "# 作為預測 起始點的一串音符\n",
    "pattern = network_input[start]\n",
    "\n",
    "# 把數字還原回音符的字典\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames)) \n",
    "\n",
    "\n",
    "prediction_output = []\n",
    "\n",
    "print(\"生成的音符:\")\n",
    "\n",
    "# 隨機生成n個音符\n",
    "for note_index in range(100):#更改range()改變音符生成的數量\n",
    "    prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = prediction_input / float(n_vocab) #正規化\n",
    "\n",
    "    #預測每一個音符的概率 \n",
    "    prediction = model.predict(prediction_input, verbose=0) \n",
    "\n",
    "\n",
    "    #挑選prediction_output裡最大的值\n",
    "    index = numpy.argmax(prediction)\n",
    "\n",
    "    #提取對應的音符\n",
    "    result = int_to_note[index]\n",
    "    print(index)\n",
    "    prediction_output.append(result)\n",
    "\n",
    "    # 將預測的一個音符放入預測窗口sequence_length，放掉原本窗口內最左邊的一個音符(窗口往右移動)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將預測的輸出轉換為音符，並從音符中創建一個MIDI文件 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_output.mid'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## \"\"\" 將預測的輸出轉換為音符，並從音符中創建一個MIDI文件 \"\"\"\n",
    "\n",
    "offset = 0\n",
    "output_notes = []\n",
    "\n",
    "# 根據模型生成的值創建音符和和弦對象\n",
    "for pattern in prediction_output:\n",
    "    # 模式是和弦\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            \n",
    "            try:\n",
    "                new_note = note.Note(int(current_note))\n",
    "#                 print(new_note)\n",
    "\n",
    "            except ValueError:\n",
    "                   pass \n",
    "                \n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "    # 模式是一個音符\n",
    "    else:\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "    # 音符之間的間距\n",
    "    offset += 0.5\n",
    "    \n",
    "# 創建樂譜\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "# 創建 MIDI 文件\n",
    "midi_stream.write('midi', fp='LAB3A_LSTM_music.mid')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
